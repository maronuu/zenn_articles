---
title: "『ディジタル画像処理』 読書メモ"
emoji: "🐕"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: []
published: false
---

## 1, 2. 入力・カメラ系
- **光ショットノイズ**
    - 光子の量、すなわち明るさの揺らぎによって発生するノイズ。暗い場所で撮影するときにより顕著に現れる。
    - SNRはsqrt(K)
        - 信号強度つまり明るさが大きいほどノイズも大きいがSNRも大きい。
        - 暗い場合はノイズは小さいが、SNRもちいさいので相対的に目立つ。
    - 回避するには
        - 感度を下げればノイズも減る。が、明るさも減るので、シャッタースピードを長くする(露光時間増やす)。F値を小さくするなどして明るさを合わせる必要がある。
- オートフォーカス(AF)
    - コントラストAF
        - ぼけていると高周波信号が少ないことから、高周波が大きくなるように山登りで最適化。時間がかかる
    - 位相差AF
        - レンズの結像位置のずれから瞬時に焦点があうべき位置を算出できる。
- 自動露光 AE
- **被写界深度**
    - 遠点から近点までの、実用上ピントが合っていると許容できる距離範囲。許容錯乱円の中に錯乱範囲が収まっていればよい。
    - 被写界深度を浅くすると、ピントが合っている範囲が狭い画像が得られる。ピンフォーカス。
    - 深くするには、
        - (前側より後方の方が深いという考え)
        - 絞り値が同じなら、焦点距離が短いほど深い
        - 焦点距離が同じなら、絞り値が大きいほど深い(パンフォーカス)
        - 被写体距離が遠いほど深い
- **F値**
    - F=(焦点距離)/(口径)
    - 開口径を表すパラメータ。レンズの明るさを表す。
    - 像面の明るさは**1/F^2**に比例する。
- 周辺光量の低下
    - **コサイン4乗則**
    - 光軸に対する入社角のCosの4乗に比例して周辺光量が低下する。レンズの絞り値には関係ない。
- **画角**
    - tan(θ/2) = (D/2)/f
    - 図をかけばわかる
- **ガンマ補正**
    - 色の色調補正である。ブラウン管ではy = x^2.2の特性があった。送信側でx^(1/γ)として全体として線形になるように補正。
    - 
- **色温度・ホワイトバランス**
    - 蛍光灯と白熱電灯はスペクトルが異なる
        - 蛍光灯: 波長の短い青に近い光
        - 白熱電灯: 波長の長い赤に近い光
        - カメラでは証明を考慮に入れたゲイン調整をしない限り、レンズに入ってきた色の波長をそのままの色として捉える。そのため、同じ物体が異なる色に写る。
        - 同じ色に移すには、ホワイトバランスにより照明とカメラの色温度を合わせる必要がある。
- **トーンカーブ**
    - 入力画像の画素値と出力画像の画素値の対応をグラフにしたもの.
    - この特性の冪乗を変えることがガンマ補正。
- **ヒストグラム平坦化**
    - 出力画像のヒストグラムが画素値全域にわたって均等に分布するように変換することで、画像のコントラストを上げる。
- **シェーディング補正**
    - ディジタルカメラでの周辺光量低下補正がある
    - フィルムカメラではこれがない。

## 3. 色
- **条件等色**とは
    - 特定の照明で同じ色に見えるということ。異なる照明では同じ色に見えるとは限らない。
- **RGBの相関**
    - 圧縮の際にはこの冗長性を利用して、色差に変換してからやる。
        - YCrCb
        - Y: 輝度
        - Cr,Cb: 色差
## 5, 6: フィルタリング
- 空間領域
    - 平均化フィルタ
        - 移動平均とるだけ
    - Gaussian Filter
        - $$h_g(x, y) = \frac{1}{2\pi\sigma^2}\exp\left(-\frac{x^2+y^2}{2\sigma^2}\right)$$
- 周波数領域
    - ローパスフィルタ
        - Gaussian Filter
            - フーリエ変換したやつ。伝達関数もGaussian。
            - $$H_g(u, v) = \exp(-2\pi^2\sigma^2(u^2+v^2))$$
    - バンドパスフィルタ
        - 1次微分
            - 勾配をとる
        - 2次微分
            - ラプラシアンをとる。
            - **ゼロ交差**がエッジに対応
        - LoG
            - 微分によりノイズが強調される
            - がうしあんでノイズ低減しつつラプラシアン
            - 帯域通過
    - **メディアンフィルタ**
        - フィルタウインドウ内の中央値を採用する出力
        - スパイクノイズ・胡麻塩ノイズといった外れ値的なノイズの除去に効果的。定常的なノイズには効果が薄い。
    - **バイラテラルフィルタ**
        - 注目画素に対して、周囲の画素を(距離のGaussian)x(輝度さのGaussian)の重みづけして和をとる
        - エッジを保存しつつ小さい振幅のGaussianノイズを除去したいときに有効
    - **non-local means filter**
        - 必ずしも近接しない小領域とその類似度を重みとした平均フィルタ
            - 類似度に応じた重み

# 7. 復元
- ボケを線形フィルタとしてみなす
- G(u, v) = F(u, v)H(u, v)
    - 逆フィルタ
        - もとのFを復元するには,
        - F = G/Hとする。
        - Hにはガウス関数や平均値フィルタを用いる。
        - **問題点: 高域のノイズを強調してしまう**
        - 問題点: Hがゼロ点を含むと逆フィルタが発散する
        - 問題点: ボケ関数Hを既知としているが実際には推定が必要。その誤差は累積する。
        - 焦点ボケ・動きボケは複雑
    - **ウィナーフィルタ**
        - G = FH + N　という劣化モデルで議論
        - F^ = W G
        - F, F^のMSEが最小となるWを伝達関数にもつフィルタ

## 8. 幾何学的変換
- 射影変換
    - (x, y, 1)で座標を表す同次座標。定数倍は意味を持たないので3x3行列成分の自由度は8。よって四点あれば計算できる。
- RANSAC
    - ランダムに対応点を選び、射影変換パラメータを最小二乗法などを使って計算する。
    - 他の点でもその射影が成り立つか(inlier)を計算
    - 投票で最善を決める(多数決、consensus)
    - エピポーラ、特徴点マッチング、などで出現
## 9. 2値画像処理
- 画像の二値化
    - p-タイル法
        - 黒色領域の割合が既知の場合
        - ピクセル値ごとの画素数分布を、値が小さい方から計算していき、ある閾値を超えたところで二分
    - モード法
        - 分布の谷を閾値にする。
    - **判別分析法(大津の閾値法)**
$$
分離度 = \frac{クラス間分散 \sigma_b^2}{クラス内分散 \sigma_w^2} = \frac{\sigma_b^2}{\sigma_t^2 - \sigma_b^2} \\
\sigma_w^2 = \frac{\omega_1\sigma_1^2 + \omega_2\sigma_2^2}{\omega_1 + \omega_2} \\
\sigma_b^2 = \frac{\omega_1(m_1 - m_t)^2 + \omega_2(m_2 - m_t)^2}{\omega_1 + \omega_2} = \frac{\omega_1\omega_2(m_1 - m_2)^2}{(\omega_1 + \omega_2)^2}
$$
を最大化する。すなわちクラス間分散を最大化すれば良い。
    - 膨張・収縮(Dilation/Erosion)
        - 周辺1pixに拡大して穴埋め
        - 外周1pixを侵食して除去
        - 適切な順番でやると、ノイズ除去
    - 輪郭追跡
        - 連結成分もとめて探索
    - 距離変換画像
        - 連結成分の各画素に背景からの最短距離を与える変換
    - 細線化(thinning)

## 10. 領域処理
- 領域分割
    - k-means
        - kを事前に指定し、(RGB, xy)でクラスタリング
        - mean-shift: TODO
## 11. パターン・図形・特徴の検出とマッチング
- テンプレートマッチング
    - 画素間の距離を計算する
- **テンプレートマッチングの高速化**
    - 多重解像度ピラミッドにする
    - 残渣逐次推定法
        - Sum Of Absを計算している時、領域内の差の絶対値を加算している。このとき、画像間の重ね合わせがずれていると、残差が急激に増大する。よって累積している差分の合計値が一定の閾値を超えたら計算を打ち切る
    - 画素値の同時生起行列を用いて、生起確率の低い画素ペアを独自性の高い画素と見做し、類似度計算に用いる参照画素として選択する。例えばテンプレート画像の選択された画素が全体の1%なら計算速度は100倍になる。
- 線画・エッジ画像のマッチング
    - 線の中心からの距離を値に持った画像をあえて作ってマッチングする。チャンファー距離
- **Harris Corner Detection** (**固有値問題の例**)
    - アルゴリズム
        1. 画像を平滑化する
        2. 各画素の微分を計算する
        3. ハリス行列を計算する
        4. ハリス行列の二つの固有値の大きさを表すコーナーネスを計算する
        5. コーナーネスの値が閾値よりも大きければコーナーと判定する
    - ある画像とそれをx,y方向に少しずらした画像の二乗差分に空間的な重みw(x,y)をかけて合計したコスト関数を計算するとハリスMatrixに対する二次形式
    - この行列の固有値を求める。片方の成分の固有値の方が圧倒的に大きいとき、それはエッジである。(特定成分のみに変化が急峻)。どちらも大きくない時、平坦。両方大きい時、コーナーである(どちらの方向からみても急峻)。
    - R Cornerness
    - R(A) = det(A) - k(tr[A])^2
        - det(A) = lambda1*lambda2
        - trace(A) = lambda1 + lambda2
- Fast Corner Detection -機械学習的アプローチ-
    - 注目点とその周りの画素値の関係を記述し、決定木によりコーナー判定する
- **LoG (Laplacian of Gaussian)**
    - 二次微分を求めたいが、ノイズをかなり強調してしまう。
    - フィルタの式(空間領域)は、Gaussianのラプラシアンを計算すればよい
- **DoG (Difference of Gaussian)**
    - L(x, y, sigma) = G(x, y, sigma) * I(x, y)
    - GはGaussian、Iは画像、Lはフィルタされた画像
    - D(x, y, sigma, k) = L(x, y, k sigma) - L(x, y, sigma)
    - で近似できる
- **SIFT特徴量のキーポイント**
    - 特徴: SIFT特徴量はスケールとオリエンテーションを持ち、画素感の拡大縮小・回転に不変である。またベクトルの総和で正規化されていれば証明変化にロバストである。
    - スケールを少しずつ大きくしたG関数と入力画像をたたみ込んだDoG画像を複数枚作る。隣接する3枚のDoG画像で、注目画素を中心とする26近傍を比較し、注目画素が極値となる要素を特徴点候補として、その位置とスケールを計算する。開口問題の影響を受けやすいエッジは除外する。残った候補を特徴点とする。(scale不変はここで)
    - オリエンテーションは、平滑化画像の勾配強度と勾配方向から、重み付き勾配方向ヒストグラムを作る。方向を36個に量子化する。最大力80%以上ピーク方向とし、オリエンテーションとする。(回転不変はここで)
    - オリエンテーションの方向に座標を回転し、短形領域を4x4に区切り、そこでまた8方向ヒストグラムを生成する。よって合計で4x4x8=128次元のベクトルとなる。これがSIFT特徴量のベクトルである。
- 応用例: 画像検索
    - BoVM
        - データ画像において、SIFTで特徴量を抽出しておく。それをKD木としてデータベースに入れておく。入力クエリが来たら、それをSIFTで抽出、検索。
            - Scale, 回転不変が類似画像検索に活きる
            - 輝度にロバスト
            - 木構造
- バイナリ特徴量
    - BRIEF, ハミング距離で高速計算できる
- Hough変換(ハフ変換)
    - 直線や円などの基本的な形状を画像から抽出する手法
    - 一連の流れ
        - エッジ検出などを適用した画像に二値化を施し、直線候補を出しておく。
        - パラメータ空間をセルに分割して、直線候補画素に対応するパラメータ(a,b)をセルに投票する。
        - 投票度数が大きなセルを探索すると、そのセルの座標が一本の直線(y = ax+b)に対応する
    - 計算方法(直線)実装可能な形
        - 直線の式を極座標で表現する
            - r = x cos \theta + y sin \theta
            - rは直線までの符号付き距離だから、画像の範囲内に収まるので有界
            - \thetaも[0, pi)でOK
            - よって有限になるので、セルの個数が有限になる。
            - 直線候補ピクセル一点に対して、パラメータ空間ではsin波が対応する。
- 画像解析フロー
    -  画像入力→特徴量抽出→特徴量に基づく認識→認識結果
(ex) まずエッジ検出，その後0 ～9 までの画像を用意し，SIFT を用いてマッチングを行う
- **Global Features**
    - 画像全体の性質を表す特徴量
    - Color
        - histogram, color histogram
    - texture
        - edge orientation hist
    - shape
        - region-based
    - motion
- **Local Features**
    - 局所的な輝度勾配
        - **SIFT** (Scale Invariant Feature Transform)
        - HOG (Histogram of Oriented Gradients)
    - Corner, 局所的な輝度特徴
        - **Harris**
        - LBP (Local Binary Pattern)
        - **FAST**
        - SUSAN


## 12. パターン認識
- 決定木
- アンサンブル学習
    - モデルの汎化性能を上げるために複数の弱学習器を組み合わせて一つの強力な学習モデルを作る。実質的には、それぞれの弱学習器の出力から多数決で最終判断を決めるという方針である。
    - Bagging
        - モデルを並列に
        - 代表例: Random Forest
    - Boosting
        - モデルを直列に
    - stacking
- サポートベクターマシン(SVM)
    - マージン最大化: 1/|w|を最大化。これが数学的に最適戦略。
- ニューラルネットワーク
    - $y = u(\sum w_jx_j - b)$
    - $E = 1/2(y-t)^2$
    - 勾配法
- パーセプトロンとSVMの違い
    - どちらも超平面で2クラス分類
    - SVMは分離平面の最近傍にある点にのみ注目するが、パーセプトロンでは全ての点に注目する。
- NNのメリット
    - 逐次学習
        - 事前学習
        - 転移学習
            - 自然画像でPretrainからの医療画像
        - 分岐が容易
            - マルチタスク
            - マルチドメイン
- 距離
    - d = (x - mu)T S^-1 (x - mu)
    - まらはのびす距離
        - 分布・確率を考慮した。ユークリッド距離では同じ距離でも広く広がっているクラスの方に属する可能性が高いようになる。
- **主成分分析** (PCA) (固有値問題の適用例)
    - 次元削減に用いられる
        - 使用容量の削減
        - 学習の安定化、ノイズへのロバストねす
    - 分散共分散行列の固有値・固有ベクトルを求める。固有値の絶対値の大きい順に第n主成分となり、重心を通り広がりの大きい順にベクトルが伸びる。これらは直交規定なのでFeatureをこれらの結合で表せる。いくつまで使うかは、恣意的、あるいはエネルギーで決める。
- 線形判別分析
    - 大津で出てきたやつの多次元版

## 13. 深層学習による画像認識と生成
## 14. 動画像処理
- 背景差分法 
    - 移動物体がない状態の画像と移動物体がある状態の画像の差分をとる
    - 純粋背景画像がないとできないのでしんどい
- フレーム間差分法
    - 1, 2フレームと2, 3フレームの差分をとり、そのANDをとると2フレームにおける移動物体がわかる。色の引き算
    - フレームのスパンによって結果が大きく異なる
    - 単一色のものだとうまくいかない
- 統計的背景差分法
    - p(w_i | I(x, y)): ある画素の画素値が与えられた時、それが前景である確率は？むり
    - ベイズでFlipして、過去の測定からp(I(x, y) | w_i)を得ておく。

- **Optical Flow**
    - ブロックマッチング
        - フレーム間でTemplate Matchingをやる
    - 勾配法
        - フレーム間の微小変化を考えて、オプティカルフローのConstraintが決まる。これを解くが不良設定なので、最小二乗法。
- 物体追跡
    - KLT Tracker
        - Harrisのコーナー検出みたいなもので特徴点を鳥、それをLK法でOpticalFlow -> 動作予測

## 15. 画像からの三次元復元
- カメラキャリブレーション
    - 内部パラメータ: センサピッチ、レンズによる歪み
    - 外部パラメータ: 世界座標に対するカメラの姿勢
- ステレオマッチング: **平行ステレオ法**
- 8点アルゴリズム
    - カメラ同士の位置関係が不明な場合のカメラモーション推定
    - 二つの画像間で複数の点の対応がとれたとすると
    - x'^T E x = 0が成り立つ。Eは3x3行列。正規化されるので自由度は8
    - 8点アルゴリズム
    - だが、最小二乗法とRANSACで安定化させる。
- アクティブステレオ
    - スポット光投影法
        - スポット状の光を対象に投影し、別の位置にあるカメラで撮影。
        - 長所: 簡単。単純。
        - 短所: 一回のがぞうで一点の計測しかできないので時間がかかる
    - ライン光投影法
        - スリットを通して線状の光を当てる。その線の歪みから奥行きを推定。
        - 長所: 一回の画像で線上の点の奥行きが計測できるため効率的
        - 短所: 画像全体をやるにはなんども走査が必要
    - 二次元パターン光投影法
        - 二次元に広がったパターン光を投影。
        - 長所: 一枚の画像から全ての点の奥行きがわかるので効率的
        - 短所: コードの複合化のコストが高い。細部の計測が難しい。

## 16. 形状の復元: 照度差ステレオ
- 白色等方な光源
- 表面の法線ベクトルn
- 光源方向 s
- 明るさ: i = n^Ts = K_d L cosθ
- これを積分すると形状